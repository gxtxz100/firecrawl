#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Firecrawl å‹å¥½å®¢æˆ·ç«¯ - äº¤äº’å¼å‘½ä»¤è¡Œå·¥å…·
========================================

ä¸€ä¸ªç®€å•æ˜“ç”¨çš„äº¤äº’å¼å‘½ä»¤è¡Œå·¥å…·ï¼Œè®©æ‚¨è½»æ¾ä½¿ç”¨ Firecrawl çš„å„ç§åŠŸèƒ½ã€‚
"""

import os
import sys
from typing import Optional

# æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
def check_venv():
    """æ£€æŸ¥æ˜¯å¦åœ¨è™šæ‹Ÿç¯å¢ƒä¸­"""
    in_venv = (
        hasattr(sys, 'real_prefix') or
        (hasattr(sys, 'base_prefix') and sys.base_prefix != sys.prefix)
    )
    return in_venv

# å¯¼å…¥å®¢æˆ·ç«¯
try:
    from firecrawl_client import FirecrawlClient, å¿«é€ŸæŠ“å–, ç½‘é¡µç»“æœ
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("\nè¯·ç¡®ä¿:")
    print("1. å·²æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ: source venv/bin/activate")
    print("2. æˆ–ä½¿ç”¨å¯åŠ¨è„šæœ¬: bash run_examples.sh")
    sys.exit(1)


def clear_screen():
    """æ¸…å±"""
    os.system('clear' if os.name != 'nt' else 'cls')


def print_header():
    """æ‰“å°æ ‡é¢˜"""
    print("\n" + "=" * 60)
    print("ğŸ”¥ Firecrawl å‹å¥½å®¢æˆ·ç«¯ - äº¤äº’å¼å·¥å…·")
    print("=" * 60)
    print()


def print_menu():
    """æ‰“å°ä¸»èœå•"""
    print("\n" + "-" * 60)
    print("è¯·é€‰æ‹©åŠŸèƒ½ï¼š")
    print("-" * 60)
    print("1. ğŸ“„ æŠ“å–å•ä¸ªç½‘é¡µ")
    print("2. ğŸ•·ï¸  çˆ¬å–æ•´ä¸ªç½‘ç«™")
    print("3. ğŸ” æœç´¢ç½‘é¡µ")
    print("4. ğŸ—ºï¸  è·å–ç½‘ç«™åœ°å›¾ï¼ˆæ‰€æœ‰é“¾æ¥ï¼‰")
    print("5. ğŸ“¦ æ‰¹é‡æŠ“å–å¤šä¸ªç½‘é¡µ")
    print("6. âš™ï¸  è®¾ç½® API å¯†é’¥")
    print("7. â„¹ï¸  æŸ¥çœ‹ä½¿ç”¨è¯´æ˜")
    print("0. ğŸšª é€€å‡º")
    print("-" * 60)


def get_user_input(prompt: str, default: Optional[str] = None) -> str:
    """è·å–ç”¨æˆ·è¾“å…¥"""
    if default:
        user_input = input(f"{prompt} (é»˜è®¤: {default}): ").strip()
        return user_input if user_input else default
    else:
        while True:
            user_input = input(f"{prompt}: ").strip()
            if user_input:
                return user_input
            print("âš ï¸  è¾“å…¥ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")


def check_api_key() -> bool:
    """æ£€æŸ¥ API å¯†é’¥æ˜¯å¦è®¾ç½®"""
    api_key = os.getenv("FIRECRAWL_API_KEY")
    if not api_key:
        print("\nâš ï¸  æœªè®¾ç½® API å¯†é’¥ï¼")
        print("\nè¯·é€‰æ‹©ï¼š")
        print("1. ç°åœ¨è®¾ç½® API å¯†é’¥")
        print("2. ç¨åè®¾ç½®ï¼ˆæŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨ï¼‰")
        choice = input("\nè¯·é€‰æ‹© (1/2): ").strip()
        
        if choice == "1":
            set_api_key()
            return True
        else:
            return False
    return True


def set_api_key():
    """è®¾ç½® API å¯†é’¥"""
    print("\n" + "=" * 60)
    print("è®¾ç½® API å¯†é’¥")
    print("=" * 60)
    print("\nè·å– API å¯†é’¥: https://firecrawl.dev")
    print("API å¯†é’¥é€šå¸¸ä»¥ 'fc-' å¼€å¤´")
    print()
    
    api_key = get_user_input("è¯·è¾“å…¥æ‚¨çš„ API å¯†é’¥")
    
    # éªŒè¯æ ¼å¼
    if not api_key.startswith("fc-"):
        print("âš ï¸  è­¦å‘Š: API å¯†é’¥é€šå¸¸ä»¥ 'fc-' å¼€å¤´")
        confirm = input("æ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ").strip().lower()
        if confirm != 'y':
            print("å·²å–æ¶ˆ")
            return
    
    # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆå½“å‰ä¼šè¯ï¼‰
    os.environ["FIRECRAWL_API_KEY"] = api_key
    print(f"\nâœ“ API å¯†é’¥å·²è®¾ç½®ï¼ˆå½“å‰ä¼šè¯æœ‰æ•ˆï¼‰")
    print("\næç¤º: è¦æ°¸ä¹…ä¿å­˜ï¼Œè¯·è¿è¡Œ:")
    print(f"  export FIRECRAWL_API_KEY='{api_key}'")
    print("  æˆ–åˆ›å»º .env æ–‡ä»¶")


def scrape_single_page():
    """æŠ“å–å•ä¸ªç½‘é¡µ"""
    print("\n" + "=" * 60)
    print("ğŸ“„ æŠ“å–å•ä¸ªç½‘é¡µ")
    print("=" * 60)
    
    if not check_api_key():
        return
    
    url = get_user_input("è¯·è¾“å…¥è¦æŠ“å–çš„ç½‘é¡µ URL")
    
    print("\né€‰æ‹©è¾“å‡ºæ ¼å¼:")
    print("1. Markdown (æ¨è)")
    print("2. HTML")
    print("3. Markdown + HTML")
    format_choice = input("è¯·é€‰æ‹© (1-3, é»˜è®¤: 1): ").strip() or "1"
    
    formats_map = {
        "1": ["markdown"],
        "2": ["html"],
        "3": ["markdown", "html"]
    }
    formats = formats_map.get(format_choice, ["markdown"])
    
    print(f"\næ­£åœ¨æŠ“å–: {url}")
    print("è¯·ç¨å€™...")
    
    try:
        client = FirecrawlClient()
        result = client.æŠ“å–ç½‘é¡µ(url, æ ¼å¼=formats)
        
        print("\n" + "=" * 60)
        print("âœ“ æŠ“å–æˆåŠŸï¼")
        print("=" * 60)
        print(f"\næ ‡é¢˜: {result.æ ‡é¢˜}")
        print(f"URL: {result.URL}")
        if result.æè¿°:
            print(f"æè¿°: {result.æè¿°}")
        print(f"\nå†…å®¹é•¿åº¦: {len(result.å†…å®¹)} å­—ç¬¦")
        
        # æ˜¾ç¤ºå†…å®¹é¢„è§ˆ
        preview = result.å†…å®¹[:500] if result.å†…å®¹ else ""
        if preview:
            print(f"\nå†…å®¹é¢„è§ˆ:\n{'-' * 60}")
            print(preview)
            if len(result.å†…å®¹) > 500:
                print(f"... (è¿˜æœ‰ {len(result.å†…å®¹) - 500} å­—ç¬¦)")
        
        # è¯¢é—®æ˜¯å¦ä¿å­˜
        save = input("\næ˜¯å¦ä¿å­˜åˆ°æ–‡ä»¶ï¼Ÿ(y/N): ").strip().lower()
        if save == 'y':
            filename = get_user_input("è¯·è¾“å…¥æ–‡ä»¶å", "output.md")
            result.ä¿å­˜ä¸ºæ–‡ä»¶(filename, "markdown")
    
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")


def crawl_website():
    """çˆ¬å–æ•´ä¸ªç½‘ç«™"""
    print("\n" + "=" * 60)
    print("ğŸ•·ï¸  çˆ¬å–æ•´ä¸ªç½‘ç«™")
    print("=" * 60)
    
    if not check_api_key():
        return
    
    url = get_user_input("è¯·è¾“å…¥èµ·å§‹ URL")
    max_pages = int(get_user_input("æœ€å¤šçˆ¬å–é¡µé¢æ•°", "10"))
    
    print(f"\nå¼€å§‹çˆ¬å–: {url}")
    print(f"æœ€å¤šçˆ¬å–: {max_pages} ä¸ªé¡µé¢")
    print("è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·ç¨å€™...")
    
    try:
        client = FirecrawlClient()
        results = client.çˆ¬å–ç½‘ç«™(url, æœ€å¤§é¡µé¢æ•°=max_pages)
        
        print("\n" + "=" * 60)
        print(f"âœ“ çˆ¬å–å®Œæˆï¼å…± {len(results)} ä¸ªé¡µé¢")
        print("=" * 60)
        
        for i, result in enumerate(results, 1):
            print(f"\n{i}. {result.æ ‡é¢˜}")
            print(f"   URL: {result.URL}")
            print(f"   å†…å®¹é•¿åº¦: {len(result.å†…å®¹)} å­—ç¬¦")
        
        # è¯¢é—®æ˜¯å¦ä¿å­˜æ‰€æœ‰ç»“æœ
        save = input(f"\næ˜¯å¦ä¿å­˜æ‰€æœ‰ {len(results)} ä¸ªé¡µé¢ï¼Ÿ(y/N): ").strip().lower()
        if save == 'y':
            for i, result in enumerate(results, 1):
                safe_title = "".join(c for c in result.æ ‡é¢˜ if c.isalnum() or c in (' ', '-', '_')).strip()[:50]
                filename = f"page_{i:03d}_{safe_title}.md"
                result.ä¿å­˜ä¸ºæ–‡ä»¶(filename, "markdown")
                print(f"  å·²ä¿å­˜: {filename}")
            print(f"\nâœ“ æ‰€æœ‰é¡µé¢å·²ä¿å­˜")
    
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")


def search_web():
    """æœç´¢ç½‘é¡µ"""
    print("\n" + "=" * 60)
    print("ğŸ” æœç´¢ç½‘é¡µ")
    print("=" * 60)
    
    if not check_api_key():
        return
    
    query = get_user_input("è¯·è¾“å…¥æœç´¢å…³é”®è¯")
    limit = int(get_user_input("è¿”å›ç»“æœæ•°é‡", "5"))
    
    # è¯¢é—®æ˜¯å¦æŠ“å–å†…å®¹
    print("\næ˜¯å¦æŠ“å–æœç´¢ç»“æœçš„å†…å®¹ï¼Ÿ")
    print("1. ä»…æ˜¾ç¤ºé“¾æ¥å’Œæè¿°ï¼ˆå¿«é€Ÿï¼‰")
    print("2. æŠ“å–å®Œæ•´å†…å®¹ï¼ˆè¾ƒæ…¢ï¼Œä½†å¯ä»¥ä¿å­˜ï¼‰")
    scrape_choice = input("è¯·é€‰æ‹© (1/2, é»˜è®¤: 1): ").strip() or "1"
    scrape_content = (scrape_choice == "2")
    
    print(f"\næ­£åœ¨æœç´¢: {query}")
    if scrape_content:
        print("æ­£åœ¨æŠ“å–å†…å®¹ï¼Œè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
    else:
        print("è¯·ç¨å€™...")
    
    try:
        client = FirecrawlClient()
        results = client.æœç´¢ç½‘é¡µ(query, ç»“æœæ•°é‡=limit, æŠ“å–å†…å®¹=scrape_content)
        
        print("\n" + "=" * 60)
        print(f"âœ“ æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
        print("=" * 60)
        
        for i, result in enumerate(results, 1):
            print(f"\n{i}. {result.get('title', 'æ— æ ‡é¢˜')}")
            print(f"   URL: {result.get('url', '')}")
            if result.get('description'):
                print(f"   æè¿°: {result.get('description')}")
            if result.get('content'):
                content_len = len(result.get('content', ''))
                print(f"   å†…å®¹é•¿åº¦: {content_len} å­—ç¬¦")
        
        # å¦‚æœæŠ“å–äº†å†…å®¹ï¼Œè¯¢é—®æ˜¯å¦ä¿å­˜
        if scrape_content and any(r.get('content') for r in results):
            save = input(f"\næ˜¯å¦ä¿å­˜æ‰€æœ‰ {len(results)} ä¸ªæœç´¢ç»“æœï¼Ÿ(y/N): ").strip().lower()
            if save == 'y':
                # åˆ›å»ºä¿å­˜ç›®å½•
                save_dir = "search_results"
                os.makedirs(save_dir, exist_ok=True)
                
                # æ¸…ç†æŸ¥è¯¢å­—ç¬¦ä¸²ä½œä¸ºæ–‡ä»¶å
                safe_query = "".join(c for c in query if c.isalnum() or c in (' ', '-', '_')).strip()[:50]
                safe_query = safe_query.replace(' ', '_')
                
                print(f"\næ­£åœ¨ä¿å­˜åˆ°ç›®å½•: {save_dir}/")
                saved_count = 0
                
                for i, result in enumerate(results, 1):
                    if result.get('content'):
                        # ç”Ÿæˆæ–‡ä»¶å
                        safe_title = "".join(c for c in result.get('title', 'æ— æ ‡é¢˜') if c.isalnum() or c in (' ', '-', '_')).strip()[:50]
                        safe_title = safe_title.replace(' ', '_')
                        filename = os.path.join(save_dir, f"{i:03d}_{safe_query}_{safe_title}.md")
                        
                        # ä¿å­˜å†…å®¹
                        try:
                            with open(filename, 'w', encoding='utf-8') as f:
                                f.write(f"# {result.get('title', 'æ— æ ‡é¢˜')}\n\n")
                                f.write(f"**URL**: {result.get('url', '')}\n\n")
                                if result.get('description'):
                                    f.write(f"**æè¿°**: {result.get('description')}\n\n")
                                f.write("---\n\n")
                                f.write(result.get('content', ''))
                            print(f"  âœ“ å·²ä¿å­˜: {filename}")
                            saved_count += 1
                        except Exception as e:
                            print(f"  âœ— ä¿å­˜å¤±è´¥ {filename}: {e}")
                
                if saved_count > 0:
                    print(f"\nâœ“ æˆåŠŸä¿å­˜ {saved_count} ä¸ªç»“æœåˆ° {save_dir}/ ç›®å½•")
                    print(f"  å®Œæ•´è·¯å¾„: {os.path.abspath(save_dir)}")
                else:
                    print("\nâš ï¸  æ²¡æœ‰å†…å®¹å¯ä¿å­˜")
    
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")


def get_site_map():
    """è·å–ç½‘ç«™åœ°å›¾"""
    print("\n" + "=" * 60)
    print("ğŸ—ºï¸  è·å–ç½‘ç«™åœ°å›¾")
    print("=" * 60)
    
    if not check_api_key():
        return
    
    url = get_user_input("è¯·è¾“å…¥ç½‘ç«™ URL")
    max_links = int(get_user_input("æœ€å¤šè¿”å›é“¾æ¥æ•°", "20"))
    
    print(f"\næ­£åœ¨è·å–ç½‘ç«™åœ°å›¾: {url}")
    print("è¯·ç¨å€™...")
    
    try:
        client = FirecrawlClient()
        links = client.è·å–ç½‘ç«™åœ°å›¾(url, æœ€å¤§é“¾æ¥æ•°=max_links)
        
        print("\n" + "=" * 60)
        print(f"âœ“ æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥")
        print("=" * 60)
        
        for i, link in enumerate(links, 1):
            print(f"\n{i}. {link.get('title', 'æ— æ ‡é¢˜')}")
            print(f"   URL: {link.get('url', '')}")
            if link.get('description'):
                print(f"   æè¿°: {link.get('description')}")
    
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")


def batch_scrape():
    """æ‰¹é‡æŠ“å–"""
    print("\n" + "=" * 60)
    print("ğŸ“¦ æ‰¹é‡æŠ“å–å¤šä¸ªç½‘é¡µ")
    print("=" * 60)
    
    if not check_api_key():
        return
    
    print("\nè¯·è¾“å…¥è¦æŠ“å–çš„ URLï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œè¾“å…¥ç©ºè¡Œç»“æŸï¼‰:")
    urls = []
    while True:
        url = input(f"URL {len(urls) + 1}: ").strip()
        if not url:
            break
        urls.append(url)
    
    if not urls:
        print("âš ï¸  æœªè¾“å…¥ä»»ä½• URL")
        return
    
    print(f"\nå°†æŠ“å– {len(urls)} ä¸ªç½‘é¡µ")
    print("è¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·ç¨å€™...")
    
    try:
        client = FirecrawlClient()
        results = client.æ‰¹é‡æŠ“å–(urls)
        
        print("\n" + "=" * 60)
        print(f"âœ“ æ‰¹é‡æŠ“å–å®Œæˆï¼å…± {len(results)} ä¸ªç»“æœ")
        print("=" * 60)
        
        for i, result in enumerate(results, 1):
            print(f"\n{i}. {result.æ ‡é¢˜}")
            print(f"   URL: {result.URL}")
            print(f"   å†…å®¹é•¿åº¦: {len(result.å†…å®¹)} å­—ç¬¦")
    
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")


def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("\n" + "=" * 60)
    print("â„¹ï¸  ä½¿ç”¨è¯´æ˜")
    print("=" * 60)
    print("""
Firecrawl å‹å¥½å®¢æˆ·ç«¯ä½¿ç”¨è¯´æ˜
============================

1. æŠ“å–å•ä¸ªç½‘é¡µ
   - è¾“å…¥ç½‘é¡µ URL
   - é€‰æ‹©è¾“å‡ºæ ¼å¼ï¼ˆMarkdown/HTMLï¼‰
   - å¯ä»¥ä¿å­˜ç»“æœåˆ°æ–‡ä»¶

2. çˆ¬å–æ•´ä¸ªç½‘ç«™
   - è¾“å…¥èµ·å§‹ URL
   - è®¾ç½®æœ€å¤šçˆ¬å–é¡µé¢æ•°
   - å¯ä»¥ä¿å­˜æ‰€æœ‰é¡µé¢

3. æœç´¢ç½‘é¡µ
   - è¾“å…¥æœç´¢å…³é”®è¯
   - è®¾ç½®è¿”å›ç»“æœæ•°é‡
   - é€‰æ‹©æ˜¯å¦æŠ“å–å†…å®¹
   - å¯ä»¥ä¿å­˜æ‰€æœ‰æœç´¢ç»“æœåˆ°æ–‡ä»¶
   - ä¿å­˜ä½ç½®: search_results/ ç›®å½•

4. è·å–ç½‘ç«™åœ°å›¾
   - è¾“å…¥ç½‘ç«™ URL
   - è·å–ç½‘ç«™æ‰€æœ‰é“¾æ¥
   - æ˜¾ç¤ºé“¾æ¥åˆ—è¡¨

5. æ‰¹é‡æŠ“å–
   - è¾“å…¥å¤šä¸ª URL
   - æ‰¹é‡æŠ“å–æ‰€æœ‰ç½‘é¡µ
   - æ˜¾ç¤ºæ‰€æœ‰ç»“æœ

6. è®¾ç½® API å¯†é’¥
   - è®¾ç½® Firecrawl API å¯†é’¥
   - è·å–å¯†é’¥: https://firecrawl.dev

æ›´å¤šä¿¡æ¯:
- æŸ¥çœ‹ firecrawl_client_README.md
- æŸ¥çœ‹ firecrawl_client_examples.py
""")


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
    if not check_venv():
        print("âš ï¸  è­¦å‘Š: æœªåœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œ")
        print("å»ºè®®ä½¿ç”¨: source venv/bin/activate")
        input("\næŒ‰ Enter ç»§ç»­...")
    
    while True:
        clear_screen()
        print_header()
        
        # æ£€æŸ¥ API å¯†é’¥çŠ¶æ€
        api_key = os.getenv("FIRECRAWL_API_KEY")
        if api_key:
            print(f"âœ“ API å¯†é’¥å·²è®¾ç½®: {api_key[:10]}...")
        else:
            print("âš ï¸  API å¯†é’¥æœªè®¾ç½®ï¼ˆæŸäº›åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨ï¼‰")
        
        print_menu()
        
        choice = input("\nè¯·é€‰æ‹© (0-7): ").strip()
        
        if choice == "0":
            print("\nğŸ‘‹ å†è§ï¼")
            break
        elif choice == "1":
            scrape_single_page()
        elif choice == "2":
            crawl_website()
        elif choice == "3":
            search_web()
        elif choice == "4":
            get_site_map()
        elif choice == "5":
            batch_scrape()
        elif choice == "6":
            set_api_key()
        elif choice == "7":
            show_help()
        else:
            print("\nâŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        if choice != "0":
            input("\næŒ‰ Enter è¿”å›ä¸»èœå•...")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

